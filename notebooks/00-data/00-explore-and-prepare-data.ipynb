{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Data\n",
    "**Attribute Information**:\n",
    "\n",
    "`InvoiceNo`: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
    "\n",
    "`StockCode`: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
    "\n",
    "`Description`: Product (item) name. Nominal.\n",
    "\n",
    "`Quantity`: The quantities of each product (item) per transaction. Numeric.\n",
    "\n",
    "`InvoiceDate`: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
    "\n",
    "`UnitPrice`: Unit price. Numeric, Product price per unit in sterling.\n",
    "\n",
    "`CustomerID`: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
    "\n",
    "`Country`: Country name. Nominal, the name of the country where each customer resides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data Processing\n",
    "\n",
    "Rows are reemoved based on the following conditions:\n",
    "- `UnitPrice` == 0\n",
    "- `CustomerID` == NaN\n",
    "- `Country` == `Unspecified`\n",
    "- `StockCode` == `POST`, `BANK CHARGES`, `PADS`, `DOT`, `CRUK`\n",
    "- `CustomerID`, where effective `Quantity` < 0\n",
    "\n",
    "Others:\n",
    "- Data type changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1 of 3: Load from a Dataset registered in AML Workspace.\n",
    "Cell below assumed that the dataset named `online-retail` is regisered in the AML `workspace`\n",
    "\n",
    "*Potential Issue:*\n",
    "\n",
    "> `online-retail.csv` is registered as dataset with both settings `properties == None` or `properties == date`. When it is loaded by the cell below using `azure.core.Dataset`, a large proportion of the column `InvoiceDate` containing dtype `datetime64[ns]` has become `NaT`. Refer to option 2 of 3, option 3 of 3 as temporary solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from azureml.core import Workspace, Dataset\n",
    "\n",
    "    # Get workspace configuration\n",
    "    workspace = Workspace.from_config()\n",
    "    print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')\n",
    "\n",
    "    # Get dataset registered within the workspace\n",
    "    dataset = Dataset.get_by_name(workspace, name='online-retail')\n",
    "\n",
    "    # Convert type Dataset to type Pandas DataFrame\n",
    "    df_orig = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opiton 2 of 3: Load from Blob Storage\n",
    "Cell below assumed that you have a container named `online-retail` and a blob named `online-retail.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:    \n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "    import pandas as pd\n",
    "\n",
    "    STORAGEACCOUNTURL= \"your-storage-account-url\"\n",
    "    STORAGEACCOUNTKEY= \"your-storage-account-key\"\n",
    "    LOCALFILENAME= \"../../data/online-retail.csv\"\n",
    "    CONTAINERNAME= \"online-retail\" # i.e. folder\n",
    "    BLOBNAME= \"online-retail.csv\" # i.e. file\n",
    "\n",
    "    #download from blob\n",
    "    blob_service_client_instance = BlobServiceClient(account_url=STORAGEACCOUNTURL, credential=STORAGEACCOUNTKEY)\n",
    "    blob_client_instance = blob_service_client_instance.get_blob_client(CONTAINERNAME, BLOBNAME, snapshot=None)\n",
    "    with open(LOCALFILENAME, \"wb\") as blob:\n",
    "        blob_data = blob_client_instance.download_blob()\n",
    "        blob_data.readinto(blob)\n",
    "\n",
    "    # LOCALFILE is the file path\n",
    "    df_orig = pd.read_csv(LOCALFILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3 of 3 : Load from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    LOCALFILENAME = \"../../src/data/online-retail.csv\"\n",
    "    df_orig = pd.read_csv(LOCALFILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "df = df_orig.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for columns with `null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0) # axis = 0 refer to column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic informaiton about `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "df = df.astype({'StockCode' : 'category',\n",
    "                'Country' : 'category',})\n",
    "\n",
    "# convert the 'Date' column to datetime format\n",
    "df['InvoiceDate']= pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# information about df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate `Quantity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Quantity']).head(10)\n",
    "df.sort_values(by=['Quantity']).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Extreme value for `Quantity`\n",
    "- `Quantity` negative, `InvoiceNo` no letter `C`, seems to mean stock adjustment, e.g. damaged, thrown away, etc\n",
    "- `UnitPrice` have value `0`. < REMOVED >\n",
    "- `CustomerID` has `nan` , what does this mean? Customer who bought things but does not register? Remove for now. < REMOVED >\n",
    "- rows where `InvoiceNo` has no letter `C`, and `Quantity` is `<0`, or `UnitPrice` is `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate `UnitPrice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['UnitPrice']).head(10)\n",
    "df.sort_values(by=['UnitPrice']).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- Extreme value for `UnitPrice`\n",
    "- `InvoiceNo` contain letter `A`, which is not in the Data Definition. Seems to mean `Adjust bad debt`, with `StockCode` `B`\n",
    "- `Stockcode` that seems not to refer to a product, includes, but not limited to, `AMAZONFEE`, `M`, `B`, `POST`, `DOT`\n",
    "    - Extract `StockCode` that contain letters to further understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unwanted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where `CustomerID` is `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where 'CustomerID' is nan\n",
    "df.dropna(subset=['CustomerID'], inplace=True)\n",
    "\n",
    "# check for columns with null\n",
    "df.isnull().sum(axis=0) # axis = 0 refer to column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- By removing `CustomerID` == `NaN`, `Description` does not contain `NaN` anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to int, then str, due to decimal point, e.g. 1234.0\n",
    "df = df.astype({'CustomerID' : int})  \n",
    "df = df.astype({'CustomerID' : str})\n",
    "\n",
    "# show statistics\n",
    "df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change text to lower case.\n",
    "df['Description'] = df['Description'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows where `Country`==`Unspecified`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where `Country`==`Unspecified`\n",
    "df = df[df['Country']!='Unspecified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if `InvoiceNo` now only contain numeric and `C` + numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all numeric with '', i.e. extract alphabets\n",
    "df_temp = df['InvoiceNo'].str.replace('\\d+', '') \n",
    "\n",
    "# Check for unique alphabets in column 'InvoiceNo'\n",
    "df_temp.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- `InvoiceNo` now only contain numeric and `C` + numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Conditions Below:\n",
    "\n",
    "- `UnitPrice` have value `0`\n",
    "- `InvoiceNo` has no letter `C`, and `Quantity` is `<0`, or `UnitPrice` is `0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UnitPrice <= 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['UnitPrice']<=0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('UnitPrice < 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['UnitPrice']<0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('UnitPrice == 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['UnitPrice']==0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "\n",
    "print('Quantity <= 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['Quantity']<=0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('Quantity < 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['Quantity']<0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('Quantity == 0   AND   InvoiceNo contain letter C')\n",
    "df[(df['Quantity']==0) & (df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "\n",
    "print('UnitPrice <= 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['UnitPrice']<=0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('UnitPrice < 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['UnitPrice']<0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('UnitPrice == 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['UnitPrice']==0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "\n",
    "print('Quantity <= 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['Quantity']<=0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('Quantity < 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['Quantity']<0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape\n",
    "print('Quantity == 0   AND   InvoiceNo not contain letter C')\n",
    "df[(df['Quantity']==0) & (~df['InvoiceNo'].str.contains('[a-zA-Z]'))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- 40 rows where `UnitPrice` == 0, `InvoiceNo` is numeric. What does this mean? Free gift? Remove for now.\n",
    "- rows where `InvoiceNo` contain letter `C`, AND `Quantity` is < 0. This is consistent now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When `UnitPrice` == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows where 'UnitPrice' == 0\n",
    "df[df['UnitPrice']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove when `UnitPrice` == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where 'UnitPrice'==0\n",
    "df.drop(df[df['UnitPrice']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate `StockCode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve rows where 'StockCode' contains alphabets\n",
    "df_temp = df[df['StockCode'].str.contains('[a-zA-Z]')] # contain any alphabets\n",
    "\n",
    "# show those unique 'StockCode' that contains alphabets\n",
    "df_temp['StockCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove digits within 'StockCode''\n",
    "df_temp = df['StockCode'].str.replace('\\d+', '')\n",
    "\n",
    "# show those unique 'StockCode' that contains alphabets\n",
    "df_temp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 'StockCode' that contains alphabets\n",
    "for alphabets in df_temp.unique():\n",
    "    if alphabets: # if alphabets is not empty\n",
    "        alphabets\n",
    "        df[df['StockCode'].str.contains(alphabets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- Remove `StockCode` == `POST`, `BANK CHARGES`, `PADS`, `DOT`, `CRUK`\n",
    "- Remove `UnitPrice < 0.01` < Gone when the above is done >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "\n",
    "# Condition used to remove rows\n",
    "condition = (df['StockCode']=='POST') | \\\n",
    "            (df['StockCode']=='BANK CHARGES') | \\\n",
    "            (df['StockCode']=='PADS') | \\\n",
    "            (df['StockCode']=='DOT') | \\\n",
    "            (df['StockCode']=='CRUK')\n",
    "\n",
    "# Remove rows based on condition stated above\n",
    "df = df[~condition]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- extreme value for `Quantity` and `UnitPrice` still exist. < Investigate >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate extreme `Quantity` values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Quantity']).head(10)\n",
    "df.sort_values(by=['Quantity']).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we are only interested in effective sales, we will exclude return of goods. For example:\n",
    "\n",
    "Initially bought,\n",
    "|InvoiceNo  |StockCode  |Description    |Unit   |Date   |UnitPrice  |TotalAmount    |Country|\n",
    "|---        |---        |---            |---    |---    |---        |---            |---|\n",
    "|538370\t    |84946\t    |ANTIQUE SILVER TEA GLASS ETCHED\t|6\t|12/12/2010 11:06\t|1.25\t|16923.0\t|United Kingdom|\n",
    "\n",
    "\n",
    "Then returned,\n",
    "|InvoiceNo  |StockCode  |Description    |Unit   |Date   |UnitPrice  |TotalAmount    |Country|\n",
    "|---        |---        |---            |---    |---    |---        |---            |---|\n",
    "|C538372\t|84946\t    |ANTIQUE SILVER TEA GLASS ETCHED\t|-2\t|12/12/2010 11:12\t|1.25\t|16923.0\t|United Kingdom|\n",
    "\n",
    "Effectively, this customer bought 4 units within that period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated records based on ['CustomerID', 'StockCode', 'UnitPrice', 'Country']\n",
    "df_duplicated = df[df.duplicated(subset=['CustomerID', 'StockCode', 'UnitPrice', 'Country'], keep=False)]\n",
    "\n",
    "# Take the sum when grouped by ['CustomerID', 'StockCode', 'UnitPrice', 'Country']\n",
    "df_effective_quantity = df_duplicated.groupby(['CustomerID', 'StockCode', 'UnitPrice', 'Country'], as_index=False, observed=True)['Quantity'].sum() \n",
    "\n",
    "# Basic Statstics\n",
    "df_effective_quantity.describe()\n",
    "\n",
    "# Display dataframe\n",
    "df_effective_quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- the idea of 'Effective Quantity' is to be used for feature engineering in [01-analyse-customer-value-by-frequency-recency-monetary-value.ipynb](01-analyse-customer-value-by-frequency-recency-monetary-value.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Processed Data to Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')\n",
    "\n",
    "datastore = workspace.get_default_datastore()\n",
    "datastore\n",
    "\n",
    "#if True:\n",
    "if False: # Replace `False` with `True` to run code below\n",
    "    filename = '../../.aml/data/online-retail-processed.csv'\n",
    "\n",
    "    # Save to local\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    Dataset.File.upload_directory('../../.aml/data', datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Dataframe as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, sep = '\\n')\n",
    "\n",
    "datastore = workspace.get_default_datastore()\n",
    "datastore\n",
    "\n",
    "#if True:\n",
    "if False: # Replace `False` with `True` to run code below\n",
    "\n",
    "    # Dataset name to register as \n",
    "    name = 'online-retail-processed'\n",
    "\n",
    "    # create a new dataset\n",
    "    Dataset.Tabular.register_pandas_dataframe(dataframe=df, \n",
    "                                            target=datastore, \n",
    "                                            name=name, \n",
    "                                            show_progress=True, \n",
    "                                            tags={'Purpose':'Tutorial'})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f332e02790cb318b361b179620298a2c5913bc96221569a4b4729c0ad3cbf061"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('azureml_py38_clustering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
